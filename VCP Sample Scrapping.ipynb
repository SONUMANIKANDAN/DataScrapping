{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c2726f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1   15                 Shell plc        Oil and Gas  272,657  20,101  \\\n",
      "0    1   15                 Shell plc        Oil and Gas  272,657  20,101   \n",
      "1    2   35                        BP        Oil and Gas  164,195   7,565   \n",
      "2    3  126                     Tesco             Retail   84,192   2,031   \n",
      "3    4  149                      HSBC            Banking   77,330  13,917   \n",
      "4    5  198                     Aviva          Insurance   64,240   2,703   \n",
      "5    6  201                 Rio Tinto             Mining   63,495  21,094   \n",
      "6    7  203           Legal & General          Insurance   62,504   2,819   \n",
      "7    8  205                  Unilever     Consumer goods   62,006   7,151   \n",
      "8    9  222      Lloyds Banking Group            Banking   58,476   7,954   \n",
      "9   10  247                  Vodafone  Telecommunication   52,931   2,424   \n",
      "10  11  294           GlaxoSmithKline    Pharmaceuticals   46,914   6,030   \n",
      "11  12  331            Anglo American             Mining   41,554   8,562   \n",
      "12  13  342               Sainsbury's             Retail   40,831     924   \n",
      "13  14  374                  Barclays            Banking   37,561   9,872   \n",
      "14  15  381               AstraZeneca    Pharmaceuticals   37,417     112   \n",
      "15  16  403  British American Tobacco     Consumer goods   35,321   9,353   \n",
      "16  17  426             Phoenix Group          Insurance   33,749  âˆ’1,151   \n",
      "17  18  463                     Linde          Chemicals   30,798   3,826   \n",
      "\n",
      "      404,379   82,000              London  \n",
      "0     404,379   82,000              London  \n",
      "1     287,272   65,000              London  \n",
      "2      66,219  231,223  Welwyn Garden City  \n",
      "3   2,957,939  219,697              London  \n",
      "4     485,481   22,062              London  \n",
      "5     102,896   49,345              London  \n",
      "6     789,066   10,743              London  \n",
      "7      85,383  148,044              London  \n",
      "8   1,200,620   57,955              London  \n",
      "9     170,749   96,941             Newbury  \n",
      "10    107,129   90,096              London  \n",
      "11     65,985   62,000              London  \n",
      "12     35,389  117,000              London  \n",
      "13  1,874,737   81,600              London  \n",
      "14    105,363   83,100           Cambridge  \n",
      "15    186,033   54,365              London  \n",
      "16    452,064    8,045              London  \n",
      "17     81,605   72,327           Guildford  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_wikipedia_table(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the table on the Wikipedia page\n",
    "        table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "        if table:\n",
    "            # Extract data from the table\n",
    "            data = []\n",
    "            for row in table.find_all('tr')[1:]:\n",
    "                columns = row.find_all(['th', 'td'])\n",
    "                row_data = [column.text.strip() for column in columns]\n",
    "                data.append(row_data)\n",
    "\n",
    "            # Create a DataFrame from the scraped data\n",
    "            df = pd.DataFrame(data, columns=data[0])\n",
    "\n",
    "            # Display the DataFrame\n",
    "            print(df)\n",
    "\n",
    "        else:\n",
    "            print(\"Table with class 'wikitable' not found on the page.\")\n",
    "\n",
    "    else:\n",
    "        print('Failed to retrieve the page. Status code:', response.status_code)\n",
    "\n",
    "# Example usage:\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_Kingdom'\n",
    "scrape_wikipedia_table(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b59af",
   "metadata": {},
   "source": [
    "# Getting all the information about TOP 50 UK Companies Revenue wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b9e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available headers: ['Rank', 'Fortune 500rank', 'Name', 'Industry', 'Revenue(USD millions)', 'Profits(USD millions)', 'Assets(USD millions)', 'Employees', 'Headquarters']\n",
      "Rank       Name                                               Industry                                 Revenue(USD millions)\n",
      "1          Shell plc                                          Oil and Gas                              272,657             \n",
      "2          BP                                                 Oil and Gas                              164,195             \n",
      "3          Tesco                                              Retail                                   84,192              \n",
      "4          HSBC                                               Banking                                  77,330              \n",
      "5          Aviva                                              Insurance                                64,240              \n",
      "6          Rio Tinto                                          Mining                                   63,495              \n",
      "7          Legal & General                                    Insurance                                62,504              \n",
      "8          Unilever                                           Consumer goods                           62,006              \n",
      "9          Lloyds Banking Group                               Banking                                  58,476              \n",
      "10         Vodafone                                           Telecommunication                        52,931              \n",
      "11         GlaxoSmithKline                                    Pharmaceuticals                          46,914              \n",
      "12         Anglo American                                     Mining                                   41,554              \n",
      "13         Sainsbury's                                        Retail                                   40,831              \n",
      "14         Barclays                                           Banking                                  37,561              \n",
      "15         AstraZeneca                                        Pharmaceuticals                          37,417              \n",
      "16         British American Tobacco                           Consumer goods                           35,321              \n",
      "17         Phoenix Group                                      Insurance                                33,749              \n",
      "18         Linde                                              Chemicals                                30,798              \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def scrape_wikipedia_table(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the table on the Wikipedia page\n",
    "        table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "        if table:\n",
    "            # Extract data from the table\n",
    "            rows = table.find_all('tr')\n",
    "\n",
    "            # Display column headers\n",
    "            header_row = rows[0].find_all('th')\n",
    "            headers = [header.text.strip() for header in header_row]\n",
    "\n",
    "            print(\"Available headers:\", headers)\n",
    "\n",
    "            # Define the subset of desired columns\n",
    "            desired_columns = [\"Rank\", \"Name\", \"Industry\", \"Revenue(USD millions)\"]\n",
    "\n",
    "            # Identify the indices of columns based on similarity scores\n",
    "            column_indices = []\n",
    "            for col in desired_columns:\n",
    "                close_matches = get_close_matches(col, headers, n=1, cutoff=0.8)\n",
    "                if close_matches:\n",
    "                    column_indices.append(headers.index(close_matches[0]))\n",
    "                else:\n",
    "                    print(f\"No close match found for column: {col}\")\n",
    "                    print(f\"Close matches: {get_close_matches(col, headers)}\")\n",
    "\n",
    "            if len(column_indices) == len(desired_columns):\n",
    "                print(\"{:<10} {:<50} {:<40} {:<20}\".format(*desired_columns))\n",
    "\n",
    "                for row in rows[1:]:  # Skip header row\n",
    "                    columns = row.find_all(['th', 'td'])\n",
    "\n",
    "                    # Extracting specific columns based on indices\n",
    "                    try:\n",
    "                        data = [columns[index].text.strip() for index in column_indices]\n",
    "\n",
    "                        # Display the row in a tabular form\n",
    "                        print(\"{:<10} {:<50} {:<40} {:<20}\".format(*data))\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error extracting data from row: {e}\")\n",
    "            else:\n",
    "                print(\"Not all desired columns are present in the table.\")\n",
    "\n",
    "        else:\n",
    "            print(\"Table with class 'wikitable' not found on the page.\")\n",
    "\n",
    "    else:\n",
    "        print('Failed to retrieve the page. Status code:', response.status_code)\n",
    "\n",
    "# Example usage:\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_Kingdom'\n",
    "scrape_wikipedia_table(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e81c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available headers: ['Rank', 'Fortune 500rank', 'Name', 'Industry', 'Revenue(USD millions)', 'Profits(USD millions)', 'Assets(USD millions)', 'Employees', 'Headquarters']\n",
      "Rank       Name                                               Industry                                 Revenue(USD millions) Profits(USD millions) Assets(USD millions) Headquarters        \n",
      "1          Shell plc                                          Oil and Gas                              272,657              20,101               404,379              London              \n",
      "2          BP                                                 Oil and Gas                              164,195              7,565                287,272              London              \n",
      "3          Tesco                                              Retail                                   84,192               2,031                66,219               Welwyn Garden City  \n",
      "4          HSBC                                               Banking                                  77,330               13,917               2,957,939            London              \n",
      "5          Aviva                                              Insurance                                64,240               2,703                485,481              London              \n",
      "6          Rio Tinto                                          Mining                                   63,495               21,094               102,896              London              \n",
      "7          Legal & General                                    Insurance                                62,504               2,819                789,066              London              \n",
      "8          Unilever                                           Consumer goods                           62,006               7,151                85,383               London              \n",
      "9          Lloyds Banking Group                               Banking                                  58,476               7,954                1,200,620            London              \n",
      "10         Vodafone                                           Telecommunication                        52,931               2,424                170,749              Newbury             \n",
      "11         GlaxoSmithKline                                    Pharmaceuticals                          46,914               6,030                107,129              London              \n",
      "12         Anglo American                                     Mining                                   41,554               8,562                65,985               London              \n",
      "13         Sainsbury's                                        Retail                                   40,831               924                  35,389               London              \n",
      "14         Barclays                                           Banking                                  37,561               9,872                1,874,737            London              \n",
      "15         AstraZeneca                                        Pharmaceuticals                          37,417               112                  105,363              Cambridge           \n",
      "16         British American Tobacco                           Consumer goods                           35,321               9,353                186,033              London              \n",
      "17         Phoenix Group                                      Insurance                                33,749               âˆ’1,151               452,064              London              \n",
      "18         Linde                                              Chemicals                                30,798               3,826                81,605               Guildford           \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def scrape_wikipedia_table(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the table on the Wikipedia page\n",
    "        table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "        if table:\n",
    "            # Extract data from the table\n",
    "            rows = table.find_all('tr')\n",
    "\n",
    "            # Display column headers\n",
    "            header_row = rows[0].find_all('th')\n",
    "            headers = [header.text.strip() for header in header_row]\n",
    "\n",
    "            print(\"Available headers:\", headers)\n",
    "\n",
    "            # Define the subset of desired columns\n",
    "            desired_columns = [\"Rank\", \"Name\", \"Industry\", \"Revenue(USD millions)\", \"Profits(USD millions)\", \"Assets(USD millions)\", \"Headquarters\"]\n",
    "\n",
    "            # Identify the indices of columns based on similarity scores\n",
    "            column_indices = []\n",
    "            for col in desired_columns:\n",
    "                close_matches = get_close_matches(col, headers, n=1, cutoff=0.8)\n",
    "                if close_matches:\n",
    "                    column_indices.append(headers.index(close_matches[0]))\n",
    "                else:\n",
    "                    print(f\"No close match found for column: {col}\")\n",
    "                    print(f\"Close matches: {get_close_matches(col, headers)}\")\n",
    "\n",
    "            if len(column_indices) == len(desired_columns):\n",
    "                print(\"{:<10} {:<50} {:<40} {:<20} {:<20} {:<20} {:<20}\".format(*desired_columns))\n",
    "\n",
    "                for row in rows[1:]:  # Skip header row\n",
    "                    columns = row.find_all(['th', 'td'])\n",
    "\n",
    "                    # Extracting specific columns based on indices\n",
    "                    try:\n",
    "                        data = [columns[index].text.strip() for index in column_indices]\n",
    "\n",
    "                        # Display the row in a tabular form\n",
    "                        print(\"{:<10} {:<50} {:<40} {:<20} {:<20} {:<20} {:<20}\".format(*data))\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error extracting data from row: {e}\")\n",
    "            else:\n",
    "                print(\"Not all desired columns are present in the table.\")\n",
    "\n",
    "        else:\n",
    "            print(\"Table with class 'wikitable' not found on the page.\")\n",
    "\n",
    "    else:\n",
    "        print('Failed to retrieve the page. Status code:', response.status_code)\n",
    "\n",
    "# Example usage:\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_Kingdom'\n",
    "scrape_wikipedia_table(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72f18b",
   "metadata": {},
   "source": [
    "## Storing the Required data in the form of Excel file for data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b80d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available headers: ['Rank', 'Fortune 500rank', 'Name', 'Industry', 'Revenue(USD millions)', 'Profits(USD millions)', 'Assets(USD millions)', 'Employees', 'Headquarters']\n",
      "Data exported to TOP_UK_Companies.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from difflib import get_close_matches\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_wikipedia_table(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the table on the Wikipedia page\n",
    "        table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "        if table:\n",
    "            # Extract data from the table\n",
    "            rows = table.find_all('tr')\n",
    "\n",
    "            # Display column headers\n",
    "            header_row = rows[0].find_all('th')\n",
    "            headers = [header.text.strip() for header in header_row]\n",
    "\n",
    "            print(\"Available headers:\", headers)\n",
    "\n",
    "            # Define the subset of desired columns\n",
    "            desired_columns = [\"Rank\", \"Name\", \"Industry\", \"Revenue(USD millions)\", \"Profits(USD millions)\", \"Assets(USD millions)\", \"Headquarters\"]\n",
    "\n",
    "            # Identify the indices of columns based on similarity scores\n",
    "            column_indices = []\n",
    "            for col in desired_columns:\n",
    "                close_matches = get_close_matches(col, headers, n=1, cutoff=0.8)\n",
    "                if close_matches:\n",
    "                    column_indices.append(headers.index(close_matches[0]))\n",
    "                else:\n",
    "                    print(f\"No close match found for column: {col}\")\n",
    "                    print(f\"Close matches: {get_close_matches(col, headers)}\")\n",
    "\n",
    "            if len(column_indices) == len(desired_columns):\n",
    "                # Create a DataFrame to store the data\n",
    "                data = []\n",
    "                for row in rows[1:]:  # Skip header row\n",
    "                    columns = row.find_all(['th', 'td'])\n",
    "                    try:\n",
    "                        row_data = [columns[index].text.strip() for index in column_indices]\n",
    "                        data.append(row_data)\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error extracting data from row: {e}\")\n",
    "\n",
    "                df = pd.DataFrame(data, columns=desired_columns)\n",
    "\n",
    "                # Export DataFrame to Excel\n",
    "                excel_filename = \"TOP_UK_Companies.xlsx\"\n",
    "                df.to_excel(excel_filename, index=False)\n",
    "                print(f\"Data exported to {excel_filename}\")\n",
    "            else:\n",
    "                print(\"Not all desired columns are present in the table.\")\n",
    "\n",
    "        else:\n",
    "            print(\"Table with class 'wikitable' not found on the page.\")\n",
    "\n",
    "    else:\n",
    "        print('Failed to retrieve the page. Status code:', response.status_code)\n",
    "\n",
    "# Example usage:\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_Kingdom'\n",
    "scrape_wikipedia_table(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd47632",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
